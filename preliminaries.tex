\chapter{Preliminaries}\label{preliminaries}
\section{Term Rewriting Systems}\label{sec:trs}
Before we can talk about the non-termination of term rewriting systems, we first need to know what exactly they are. We will consider two types of rewriting systems: the ``normal'' Term Rewriting Systems and secondly Many-Sorted Term Rewriting Systems. They are both needed in order to be able to alter existing non-termination techniques (for the ``normal'' systems) into the many-sorted case. We will start off with the definition of the ordinary term rewriting system. For more details, see for example \cite{Klop:1993:TRS:162552.162559}.
\subsection{Term Rewriting System}
Intuitively, a term rewriting system (TRS) is a set of rewriting rules that can be applied on term, which in its place can be seen as either variables or functions with terms as arguments. More formally it can be seen as a tuple containing an alphabet ($\Sigma$) and a set of rewriting rules ($R$). $\Sigma$ typically contains an infinite set of variables ($\mathcal{V}$) combined with a set of function symbols ($\mathcal{F}$). Every function symbol has an arity, which is the number of arguments it takes. The arity may be zero, in which case it can also be seen as a constant term.  

\subsubsection*{Terms}
We define the possible terms in an alphabet $\Sigma$ as $\textit{Ter}\left(\Sigma\right)$. This set firstly contains the variables in $\Sigma$. Secondly, any function in $\Sigma$ of which all its arguments are in $\textit{Ter}\left(\Sigma\right)$, is also added to the set. More formally: 
\begin{definition}\label{def:untypedterms}
The set $\textit{Ter}\left(\Sigma\right)$ is inductively defined as follows:
\begin{itemize}
    \itemsep -0.5em
    \item[-] each variable $v \in \mathcal{V}$ is in $\textit{Ter}\left(\Sigma\right)$
    \item[-] if $f \in \Sigma$ has arity $n$ and $s_1, \dots, s_n$ are in $\textit{Ter}\left(\Sigma\right)$, then $f(s_1, \dots, s_n) \in \textit{Ter}(\Sigma)$
\end{itemize}
\end{definition}

\subsubsection*{Positions}
Positions can be seen as pointers to specific subterms within a term. We define these positions by $\textit{Pos}\left(t\right)$ where $t \in \textit{Ter}\left(\Sigma\right)$:
\begin{definition}
$$
\textit{Pos}(t) = \left\{\begin{array}{ll}
        \left\{\epsilon\right\}, & \text{if } t \in \mathcal{V}\\
        \left\{\epsilon\right\} \cup \{i.p \mid 1 \leq i \leq n \text{ and } p  \in \textit{Pos}(t_i)\} , & \text{if } t = f(t_1, \dots, t_n)
        \end{array}\right.
$$
\end{definition}
We denote $\left.t\right|_p$ when we want to indicate the position $p$ within term $t$. The identity case is $\left.t\right|_\epsilon = t$.

\textbf{Example 2.1}: Suppose we have variables $\{ x, y \} \subseteq \mathcal{V}$ and function symbols $\mathcal{F} = \{ plus, suc, 0\}$ with arities of 2, 1 and 0 respectively. With these variables and function symbols we can create an alphabet $\Sigma = \mathcal{V} \cup \mathcal{F}$, then we can create terms from $\textit{Ter}(\Sigma)$. Possible terms include $t_1 = x$, $t_2 = 0$, $t_3 = plus(x, y)$, $t_4 = suc(plus(0, x))$. Positions of these terms are as follows: $\textit{Pos}(t_1) = \{ \epsilon \}$, $\textit{Pos}(t_2) = \textit{Pos}(t_1), \textit{Pos}(t_3) = \{ \epsilon, 1.\epsilon, 2.\epsilon \} \text{ and }\textit{Pos}(t_4) = \{ \epsilon, 1.\epsilon, 1.1.\epsilon, 1.2.\epsilon \}$. We can for example take $\left. t_3\right|_{2.\epsilon} = y$.

\subsubsection*{Substitutions}
Substitutions are mappings from variables to terms. This means that a substitution applied to a function symbol is equal to a substitution applied to the arguments of the function symbol separately:
\begin{definition}
A substitution is a mapping $\sigma = \{ v_1 \leftarrow t_1, \dots, v_n \leftarrow t_n \}$ ($\{ v_1, \dots, v_n \} \subseteq \mathcal{V}$, $\{ t_1, \dots, t_n\} \subseteq \textit{Ter}(\Sigma)$), which, when applied to a term, replaces all instances in the term of $v_i$ with $t_i$.
\end{definition}

\textbf{Example 2.2}: \textit{Continuation of example 2.1}. Let us say we want to create a substitution $\sigma_1 = \{ 0 \leftarrow x, suc(y) \leftarrow y \}$. We can apply this substitution to terms as follows: $\sigma_1(t_1) = \sigma_1(t_2) = 0$, $\sigma_1(t_3) = plus(\sigma_1(x), \sigma_1(y)) = plus(0, suc(y))$ and $\sigma_1(t_4) = suc(\sigma_1(plus(0, x))) = suc(plus(0, \sigma_1(x))) = suc(plus(0, 0))$.

\subsubsection*{Rewrite rules}
We can now create a notion for rewrite rules. These rules have a left and right side, the left side cannot be a variable, otherwise the rule can be applied to any term. Also, the right side cannot contain any variables that do not exist on the left side. This is because otherwise, the variable cannot be given a value when applying the rule.
\begin{definition}
A rewrite rule is defined as $r_i : l \rightarrow r$. Here, $l$ and $r$ are terms in $\textit{Ter}(\Sigma)$. $r_i$ is an optional name for the rule. Furthermore, $l$ cannot be a variable and if $\textit{Var}(t)$ defines the variables in a term $t$, $\textit{Var}(r) \subseteq \textit{Var}(l)$. 
\end{definition}

\textbf{Example 2.3}: \textit{Continuation of example 2.1}. We can now create rules from the terms we have defined:\newline
$$
\begin{array}{lrcl}
    r_1: & plus(x, y) & \rightarrow & x \\
    r_2: & plus(x, y) & \rightarrow & 0 \\
    r_3: & plus(x, y) & \rightarrow & suc(plus(0, x))\\
    r_4: & suc(plus(0, x)) & \rightarrow & x\\
    r_5: & suc(plus(0, x)) & \rightarrow & 0\\
    r_6: & plus(x, y) & \rightarrow & plus(x, y) \\
    r_7: & suc(plus(0, x)) & \rightarrow & suc(plus(0, x))\\
    r_8: & 0 & \rightarrow & 0
\end{array}
$$
Note that these are the only possible rules we can create from the four terms we defined previously. The other combinations of terms all either break the rule that the LHS cannot be a variable, or break the rule that the RHS may only contain variables that are also on the LHS.

\subsubsection*{Rewrite relation}
We can now define how these rules can be used to rewrite terms. Intuitively, we can apply a rule to some term when there is a subterm of that term that matches the left side of given rule. Then the resulting term is the original term where the chosen subterm gets replaced by the right side of the rule.
\begin{definition}
We denote $t_1 \rightarrow_R t_2$ if a term $t_1$ can be rewritten, using TRS $R$, to a term $t_2$. A term $t_1$ can be rewritten using the rule $l \rightarrow r \in R$ to $t_2$, if there is a subterm in $t_1$ at position $p$, such that there is a substitution $\sigma$ for which holds that $\left.t_1\right|_p = \sigma(l)$. Then $t_2 = t_1\left[ \sigma(r) \right]_p$. 

Here, $t_1\left[ \sigma(r) \right]_p$ means that position $p$ of term $t_1$ gets replaced by $\sigma(r)$. Note that when we have two terms $s_1$ and $s_2$ and a substitution $\sigma$ for which holds that $\sigma(s_1) = s_2$, we say that $s_1$ matches $s_2$.
\end{definition}
\textbf{Example 2.4}: Suppose we have a term rewrite system with the rules $r_1: add(x, 0) \rightarrow x$, $r_2: add(x, suc(y)) \rightarrow suc(add(x, y))$. We can represent $1 + 2$ in a term $t$ as $add(suc(0), suc(suc(0)))$. We can rewrite $t$ using $r_2$, we choose position $p = \epsilon$, then $\sigma = \{ x \leftarrow suc(0), y \leftarrow suc(0) \}$. The resulting term then becomes $t\left[ \sigma(suc(add(x, y))) \right]_\epsilon = t\left[ suc(add(suc(0), suc(0))) \right]_\epsilon = suc(add(suc(0), suc(0)))$. We then get:
$$
\begin{array}{rl}
                  & add(suc(0), suc(suc(0))) \\
    \rightarrow_R & suc(add(suc(0), suc(0))) \\
    \rightarrow_R & suc(suc(add(suc(0), 0))) \\
    \rightarrow_R & suc(suc(suc(0)))
\end{array}
$$

\subsection{Many-Sorted Term Rewriting System}
\subsubsection{Many-Sorted or First-Order}
Many-Sorted term rewriting systems are much like the previously explained term rewriting systems. The difference is that in many-sorted term rewriting systems, all elements of the alphabet $\Sigma$ have types. More precisely, they are first-order typed. 

A first-order type is an identifier that puts terms in classes. We define arrow types and base types. Arrow types are used to give types to function symbols. A function symbol $f$ could be typed as $\alpha \rightarrow \beta \rightarrow \gamma$. We say that $\gamma$ is the output type of $f$. We can also see that $f$ has two arguments, the first one must be of type $\alpha$, the second one of type $\beta$. Base types are types that do not contain arrows.

First-order types constrict variables to use base types. Functions must have a base type as its output type and all of its arguments must be first-order typed.

We could for example have the function $plus$ typed as $nat \rightarrow nat \rightarrow nat$, denoted $plus :: nat \rightarrow nat \rightarrow nat$. $plus$ is now a function that takes two arguments of type $nat$ and gives back a term of type $nat$. Another function $eq$ could be typed as follows: $eq :: nat \rightarrow nat \rightarrow bool$. This function takes two arguments of type $nat$ and gives back a term of type $bool$. 

\subsubsection{Rewriting system}
We do not need to change many of the previous definitions, we just need to make sure that every element of the alphabet gets a type and that all operations defined are not allowed to break the typing. For example, a term of type $\alpha$ may not be substituted with one of type $\beta$.
\subsubsection{Alphabet}
We define the alphabet of a many-sorted TRS as $\Sigma$, containing the set of variables $\mathcal{V}$ and the set of function symbols $\mathcal{F}$ as before. Now we extend this by saying that every variable has a base type. The function symbols are extended such that every function gets first-order types as well. 
\begin{definition}
The alphabet $\Sigma$ of a many sorted TRS is defined as follows:
\begin{itemize}
    \itemsep -0.4em
    \item[-] each variable $v \in \mathcal{V}$ is in $\Sigma$
    \item[-] each function $f \in \mathcal{F}$ is in $\Sigma$
    \item[\bf-] each variable $v \in \mathcal{V}$ has a base type $\tau$
    \item[\bf-] each function $f \in \mathcal{F}$ in the form $f(s_1, \dots, s_n)$ with arity $n$ has type $\tau_1 \rightarrow \dots \rightarrow \tau_{n+1}$
\end{itemize}
\end{definition}

\subsubsection{Terms}
We redefine the possible terms in an alphabet $\Sigma$ as $\textit{Ter}\left(\Sigma\right)$ for many-sorted term rewriting systems. This definition is much like definition \ref{def:untypedterms} but contains extra typing checks: 
\begin{definition}
The set $\textit{Ter}\left(\Sigma\right)$ is inductively defined as follows:
\begin{itemize}
    \itemsep -0.5em
    \item[-] each variable $v \in \mathcal{V}$ is in $\textit{Ter}\left(\Sigma\right)$
    \item[-] if $f :: \alpha_1 \rightarrow \dots \rightarrow \alpha_{n+1} \in \Sigma$, $s_1, \dots, s_n$ are in $\textit{Ter}\left(\Sigma\right)$ \textbf{and} $\alpha_i = \text{Type}(s_i)$ for $i \in [1, n]$, then $f(s_1, \dots, s_n) \in \textit{Ter}(\Sigma)$
\end{itemize}
\end{definition}

\subsubsection{Substitutions and rewrite rules}
As previously explained, we also need to make sure that when using substitutions, both sides of the substitution have the same type. When it comes to rules, it is much like the case in the substitutions, both sides of the rules must have the same type.
\begin{definition}
A substitution is a mapping $\sigma = \{ v_1 \leftarrow t_1, \dots, v_n \leftarrow t_n \}$ ($\{ v_1, \dots, v_n \} \subseteq \mathcal{V}$, $\{ t_1, \dots, t_n\} \subseteq \textit{Ter}(\Sigma)$), which, when applied to a term, replaces all instances in the term of $v_i$ with $t_i$.  

If $\textit{Type}(t)$ gives the (output) type of a term, then $\textit{Type}(t_i) = \textit{Type}(v_i)$ for all $i \in [ 0, n ]$.
\end{definition}

\begin{definition}
A rewrite rule in a many-sorted TRS is defined as $r_i : l \rightarrow r$. Here, $l$ and $r$ are terms in $\textit{Ter}(\Sigma)$. $r_i$ is an optional name for the rule. Furthermore, $l$ cannot be a variable and if $\textit{Var}(t)$ defines the variables in a term $t$, $\textit{Var}(r) \subseteq \textit{Var}(l)$ and \textbf{$\textit{Type}(l) = \textit{Type}(r)$}. 
\end{definition}

\textbf{Example 2.5}: Let us create an alphabet $\Sigma$ consisting of the variables $\mathcal{V} = \{ x, y, z\}$. The types of these variables are as follows: $x$ and $z$ have type $nat$ and $y$ has type $bool$. Now we create the set of function symbols $\mathcal{F} = \{ eq, suc, true \}$. $eq$ has type $nat \rightarrow nat \rightarrow bool$, $suc$ has type $nat \rightarrow nat$ and $true$ is of type $bool$. Substitutions such as $\sigma_1 = \{ y \leftarrow true \}$ and $\sigma_2 = \{ y \leftarrow eq(suc(x), x) \}$ are possible, but we cannot create a substitution like $\sigma_2 = \{ x \leftarrow y \}$, since the type of $x$ ($\alpha$) does not match the type of $y$ ($\beta$).

\textbf{Example 2.6}: \textit{Continuation of Example 2.5}. To create an entire TRS, we also need some rewriting rules. With the alphabet we just created we can create the following rule: 
$$
\begin{array}{lrcl}
    r_1: & eq(x, x) & \rightarrow & true \\
    r_2: & eq(suc(x), suc(z)) & \rightarrow & eq(x, z)
\end{array}
$$
These rules are correctly typed as the output type of $eq$ is $bool$ and the types of $true$ is also $bool$. Also the arguments supplied to $eq$ all have type $nat$. 

\section{Unifiers}
A unifier of two terms is a substitution $\sigma$ such that, when applied to two (or more) terms, the resulting terms are all equal. 
\begin{definition}
Given two terms $t_1$ and $t_2$, a unifier $\sigma$ is a substitution such that $\sigma(t_1) = \sigma(t_2)$.
\end{definition}

\textbf{Example 2.6} \textit{We will omit types in this example, in further examples we always talk about many-sorted systems, but sometimes types are omitted}. Let us take two terms $t_1 = f(g(x), y)$ and $t_2 = f(z, g(z))$. To unify these two terms, we can use a unifier $\sigma_1 = \{ g(z) \leftarrow y, g(x) \leftarrow z \}$.

\section{Most General Unifiers}
We will now look at what happens when we apply multiple substitutions on one term. If we have multiple substitutions to apply to $t$, for example $\sigma_1$ and $\sigma_2$, we denote it as $t\sigma_1\sigma_2$. If we see the substitution as a function we can write $\sigma_2\left( 
\sigma_1(t)\right)$.

\textbf{Example 2.7}: \textit{We will omit types in this example}. Let us take a term $t = f(x, g(y))$ and substitutions $\sigma_1 = \{ f(x, x) \leftarrow x\}$, $\sigma_2 = \{ y \leftarrow x, 0 \leftarrow y \}$. If we want to know $t\sigma_1\sigma_2$, or equivalently, $\sigma_2(\sigma_1(t))$, we can first take $t\sigma_1 = f(f(x, x), g(y))$. Then from there we apply $\sigma_2$, which brings us to $\sigma_2(f(f(x, x), g(y))) = f(f(x, x), g(0))$.

We can also create a definition for a most general unifier, often denoted as a function $\textit{mgu}(s, t)$. A unifier $\sigma$ is a most general unifier of two terms $s$ and $t$, if it unifies $s$ and $t$, and given any other unifier of these terms, this can be created using a substitution on $\sigma$:
\begin{definition}
Given two terms $t_1$ and $t_2$, a most general unifier $\sigma$ is a substitution such that:
\begin{itemize}
    \itemsep -.4em
    \item[-] $\sigma$ unifies $t_1$ and $t_2$
    \item[-] given any other unifier $\sigma'$ that unifies $t_1$ and $t_2$, $\sigma'$ can be created using a substitution $\omega$ on $\sigma$
\end{itemize}
\end{definition}

If a unifier for two terms exist, then there also exists a most general unifier\cite{BUSS19981}. The most general unifier is also unique under variable renaming. 

\textbf{Example 2.8}: \textit{We will omit types in this example}. Take terms $s = f(x, h(y, z))$ and $t = f(z, h(0, x))$, it is clear that we can create a substitution that will unify these terms: $\sigma_1 = \{ z \leftarrow x, 0 \leftarrow y \}$, then $s\sigma_1 = t\sigma_1$. This substitution is also the most general unifier of these terms. To show this we can take another substitution $\sigma_2 = \{ f(x, x) \leftarrow x, f(x, x) \leftarrow z, 0 \leftarrow y \}$. Note that we can create $\sigma_2$ using $\sigma_1$: $\sigma_2 = \sigma_1\omega_1$, take $\omega_1 = \{ f(x, x) \leftarrow z\}$.

\section{Cora}
Cora, standing for COnstrained Rewriting Analyser\cite{Cora2019}, will be used for as the basis of the non-termination analyser resulting from this paper. Cora is a work in progress analysis tool for all kinds of TRSs. As far as the usage for Mara goes, it can be seen as an parser for input TRSs. The only usable part for us in Cora is what is defined in section \ref{sec:trs}. The program is written in Java and uses ANTLR\cite{Parr:2013:DAR:2501720} as its parsing tool.

\subsection{Terms}
Perhaps the most important tool we can use in Cora are the predefined Term types. The terms come in two major types: variables and functions. Each implementation of the Term interface has to provide the following (listed are the most interesting ones) functionality: 
\begin{enumerate}
    \itemsep0em 
    \item Getting (all possible) subterms,
    \item (for non variables) obtaining the function symbol,
    \item Equality comparison against other terms,
    \item Replacing a position with a term,
    \item Substitutions,
    \item Matching a term to another term.
\end{enumerate}
All of these functionalities have typing checks within them. 
\subsection{Rules}
To create rules for use in rewriting systems, Cora has an interface Rule. The most interesting functionalities are: 
\begin{enumerate}
    \itemsep0em
    \item Getting the left or right side of the rule,
    \item Checking if the rule can be applied to some term,
    \item Actually applying the rule to some term.
\end{enumerate}
Just as with the terms, all of these actions have typing checks. 
\subsection{Term rewriting system}
Within Cora, a term rewriting system is basically just a list of rules. Cora can import term rewriting systems using three file formats: \texttt{.mstrs} (Many-Sorted TRSs), \texttt{.trs} (untyped TRSs) and \texttt{.cora} (an internal file type, also sorted). 